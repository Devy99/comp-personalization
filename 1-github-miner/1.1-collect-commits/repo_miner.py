import os, csv, json, argparse
from pydriller import Repository
from wrapt_timeout_decorator import *

class ObjectEncoder(json.JSONEncoder):
    def default(self, obj):
        if hasattr(obj, "__dict__"):
            return {key:value for key, value in obj.__dict__.items() if not key.startswith("_")}
        return super().default(obj)

class Commit(object):
    def __init__(self, modification, repo_name, ext_data_count):
        self.author = modification.author.name
        self.email = modification.author.email
        self.id = modification.hash
        self.date = modification.author_date
        self.repository = repo_name
        self.branches = modification.branches
        self.in_main_branch = modification.in_main_branch
        self.changed_files = []

        changed_files = []
        n_added_lines, n_removed_lines, n_changed_methods = 0, 0, 0
        for file in modification.modified_files: 
            if is_java(file.filename): 
                n_changed_methods += len(file.changed_methods)
                n_added_lines += file.added_lines
                n_removed_lines += file.deleted_lines
                changed_files.append(ChangedFile(file))
        
        self.added_line = n_added_lines
        self.removed_line = n_removed_lines
        self.diff_size = n_added_lines + n_removed_lines
        self.n_changed_methods = n_changed_methods
        self.changed_files = changed_files
        self.data_id = ext_data_count

class ChangedFile(object):
    def __init__(self, file):
        self.old_path = file.old_path
        self.new_path = file.new_path
        self.filename = file.filename
        self.change_type = file.change_type.name
        #self.diff = file.diff
        self.added_lines = file.added_lines
        self.deleted_lines = file.deleted_lines
        #self.source_code = file.source_code
        #self.source_code_before = file.source_code_before
        
        self.changed_methods = file.changed_methods
        self.methods_before = file.methods_before
        self.methods_after = file.methods

        self.nloc = file.nloc
        self.complexity = file.complexity
        self.token_count = file.token_count


class ChangedMethod(object):
    def __init__(self, method):
        self.name = method.name
        self.long_name = method.long_name
        self.start_line = method.start_line
        self.end_line = method.end_line
         

def is_java(filename: str):
    splitted = filename.split('.')
    return splitted[-1] == 'java' if len(splitted) > 0 else False
    

def export_data(commit: Commit, commits_filepath: str, ext_dir: str):
    # Init CSV if not exists
    if not os.path.isfile(commits_filepath):
        with open(commits_filepath, 'w', newline='') as f:
            writer = csv.writer(f)  
            writer.writerow(['author', 'email', 'commit_id', 'date', 'repository', 'branches', 'in_branch_main', 'changed_files', 'diff_size', 'added_line', 'removed_line', 'changed_methods', 'data_id'])

    # Update with commit general info
    with open(commits_filepath, 'a', newline='') as f:
        writer = csv.writer(f)  
        branches = "    ".join([branch for branch in commit.branches])    
        writer.writerow([commit.author, commit.email, commit.id, commit.date, commit.repository, branches, commit.in_main_branch, len(commit.changed_files), commit.diff_size,
                         commit.added_line, commit.removed_line, commit.n_changed_methods, commit.data_id])
    
    # Generate external data JSON file
    if not os.path.exists(ext_dir): os.makedirs(ext_dir)
    ext_file = {'data_id': commit.data_id, 'changed_files': commit.changed_files}
    with open(os.path.join(ext_dir, f'ext_{commit.data_id}.json'), 'w') as f:
        f.write(json.dumps(ext_file, cls=ObjectEncoder, indent=4))
    

@timeout(60) 
def retrieve(commit: any, repo_name: str, ext_data_count: int): 
    return Commit(commit, repo_name, ext_data_count)


def get_argparser() -> argparse.ArgumentParser:
    """
    Get the configured argument parser
    """

    parser = argparse.ArgumentParser(description='optional arguments')
    parser.add_argument('--commits_filepath', '-c',
                        metavar='FILEPATH',
                        dest='commits_filepath',
                        required=False,
                        type=str,
                        default='commits.csv',
                        help='Filepath of the commits CSV file generated by the script')
    parser.add_argument('--ext_dir', '-d',
                        metavar='PATH',
                        dest='ext_dir',
                        required=False,
                        type=str,
                        default='ext-data',
                        help='Name of the directory where to save external data for each commit')

    required = parser.add_argument_group('required arguments')
    required.add_argument('--repos_filepath', '-f',
                        metavar='FILEPATH',
                        dest='filepath',
                        required=True,
                        type=str,
                        help='Filepath of the JSON containing the repositories to mine')
    
    return parser

if __name__ == '__main__':  

    # Read arg parameters
    parser = get_argparser()
    args = parser.parse_args()

    # Load retrieved repositories
    with open(args.filepath) as f:
        repos = json.load(f)

    ext_data_count = 0
    for repo in repos:
        print(f'Mining the repo name: {repo["name"]} available on {repo["url"]} ...')

        try:
            for modification in Repository(repo["url"], only_modifications_with_file_types=['.java']).traverse_commits():
                try:
                    commit = retrieve(modification, repo['name'], ext_data_count)
                    if commit.n_changed_methods == 0: continue
                except TimeoutError: 
                    continue
                
                export_data(commit, args.commits_filepath, args.ext_dir)
                ext_data_count += 1
        except Exception as ex:
            print(f'Skipping repo {repo}: Error: {ex}')
            continue

